{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e42b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import floor, exp, sqrt, pi, cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7021e526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.0-cp39-cp39-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 8.3/8.3 MB 695.8 kB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\пользователь\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.23.5)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.3-cp39-cp39-win_amd64.whl (40.2 MB)\n",
      "     -------------------------------------- 40.2/40.2 MB 554.5 kB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.0 scipy-1.9.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# Установка библиотеки sklearn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8a62b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_2(x):    \n",
    "    return round(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364ebb7",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, x_val, y_val):\n",
    "   \n",
    "    y_pred = model.predict(x_val)\n",
    "    \n",
    "    res = 0\n",
    "\n",
    "    for i in range(len(y_val)):\n",
    "        res += abs(y_pred[i] - y_val[i])\n",
    "        \n",
    "    return res / len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625aa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_featured_data(config,data):\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        row = []\n",
    "        for feature in config:\n",
    "            row.append(data[i][feature])\n",
    "        new_data.append(row)\n",
    "    return new_data\n",
    "\n",
    "def grid_search_solution(\n",
    "        model,\n",
    "        model_configs,\n",
    "        x_train, y_train,\n",
    "        x_val, y_val):\n",
    "    \"\"\"\n",
    "    Принимает набор конфигураций модели линейной регрессии и находит лучшую из них\n",
    "    с помощью алгоритма grid search.\n",
    "    Для оценки точности модели на валидационной выборке используется функция score_model.\n",
    "\n",
    "    Аргументы:\n",
    "        model: Модель.\n",
    "        model_configs: Список конфигураций модели линейной регрессии.\n",
    "                       Каждая конфигурация — список номеров факторов,\n",
    "                       которые используются для обучения модели.\n",
    "        x_train: Список объектов обучающей выборки.\n",
    "        y_train: Список значений предсказываемой характеристики для объектов из обучающей выборки.\n",
    "                 Значение на $i$-ой позиции в списке соответствует $i$-ому объекту обучающей выборки.\n",
    "        x_val: Список объектов валидационной выборки.\n",
    "        y_val: Список значений предсказываемой характеристики для объектов из валидационной выборки.\n",
    "               Значение на $i$-ой позиции в списке соответствует $i$-ому объекту валидационной выборки.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Возвращает пару значений: лучшая конфигурация, точность модели с данной конфигурацией\n",
    "        на валидационной выборке.\n",
    "    \"\"\"\n",
    "    max_cfg = ([-1], 9999)\n",
    "    for config in model_configs:\n",
    "        # model.set_params(model_configs[0][0])\n",
    "        x_featured = make_featured_data(config,x_train)\n",
    "        model.fit(x_featured, y_train)\n",
    "        x_val_featured = make_featured_data(config,x_val)\n",
    "        if (score := score_model(model,x_val_featured , y_val)) < max_cfg[1]:\n",
    "            max_cfg = (config, score)\n",
    "    max_cfg = (max_cfg[0], round_to_2(max_cfg[1]))\n",
    "    return max_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, frac=0.9):\n",
    "    data_x_y = []\n",
    "    \n",
    "    with open(file_path) as f:\n",
    "        cnt = 0\n",
    "        \n",
    "        for line in f:\n",
    "            if cnt == 0:\n",
    "                cnt += 1\n",
    "                continue\n",
    "                \n",
    "            l = line.strip().split(',')\n",
    "            data_x_y.append(([float(x) for x in l[:-1]], float(l[-1])))  \n",
    "            \n",
    "            cnt += 1\n",
    "            \n",
    "    cut_n = floor(frac * len(data_x_y))\n",
    "            \n",
    "    train_x_y = data_x_y[:cut_n]\n",
    "    val_x_y = data_x_y[cut_n:]\n",
    "    \n",
    "    train_x, train_y = [], []\n",
    "    \n",
    "    for x, y in train_x_y:\n",
    "        train_x.append(x)\n",
    "        train_y.append(y)\n",
    "        \n",
    "    val_x, val_y = [], []\n",
    "    \n",
    "    for x, y in val_x_y:\n",
    "        val_x.append(x)\n",
    "        val_y.append(y)\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "def grid_search_test():\n",
    "    def split_df_to_xs_and_ys(df):\n",
    "        xs = []\n",
    "        ys = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            xs.append([row['x1'], row['x2'], row['x3'], row['x4']])\n",
    "            ys.append(row['y'])\n",
    "            \n",
    "        return xs, ys\n",
    "        \n",
    "    data_x_train_example_1 = [[1, -33], [2, -21], [3, -34234]]\n",
    "    data_y_train_example_1 = [1, 2, 3]\n",
    "    \n",
    "    data_x_val_example_1 = [[4, -231], [5, -342341], [6, -23]]\n",
    "    data_y_val_example_1 = [4, 5, 6]\n",
    "    \n",
    "    configs_example_1 = [[0], [1]]\n",
    "    \n",
    "    res_example_1 = ([0], 0)\n",
    "    \n",
    "    assert grid_search_solution(LinearRegression(),\n",
    "                                configs_example_1,\n",
    "                                data_x_train_example_1, data_y_train_example_1,\n",
    "                                data_x_val_example_1, data_y_val_example_1) == res_example_1\n",
    "    \n",
    "    data_x_train_example_2, data_y_train_example_2, \\\n",
    "        data_x_val_example_2, data_y_val_example_2 = process_data('grid_search_test_data.csv', frac=0.9)\n",
    "    \n",
    "    configs_example_2 = [[0], [0, 1], [0, 1, 2], [2, 3], [1]]\n",
    "    \n",
    "    res_example_2 = ([0, 1, 2], 0.26)\n",
    "    \n",
    "    assert grid_search_solution(LinearRegression(),\n",
    "                                configs_example_2,\n",
    "                                data_x_train_example_2, data_y_train_example_2,\n",
    "                                data_x_val_example_2, data_y_val_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02796d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacba8e",
   "metadata": {},
   "source": [
    "# Метод дихотомии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a680a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_solution(f, a, b, eps):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума заданной функции в заданном интервале с помощью метода дихотомии.\n",
    "    \n",
    "    Аргументы:\n",
    "        f: Функция от одного аргумента, минимум которой необходимо найти.\n",
    "        a: Левая граница интервала, в котором происходит поиск минимума.\n",
    "        b: Правая граница интервала, в котором происходит поиск минимума.\n",
    "        eps: Допустимая погрешность при поиске минимума.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Возвращает координату точки, в которой достигается минимальное значение функции.\n",
    "        Координата должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576aeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_test():\n",
    "    f_example_1 = lambda x: x ** 2\n",
    "    \n",
    "    a_example_1 = -2\n",
    "    b_example_1 = 5\n",
    "    eps_example_1 = 0.01\n",
    "    \n",
    "    res_example_1 = 0\n",
    "    \n",
    "    assert dichotomous_search_solution(f_example_1, a_example_1, b_example_1, eps_example_1) == res_example_1\n",
    "    \n",
    "    f_example_2 = lambda x: (exp(2 * (x - 2)) + 1) * (x + 1) ** 2\n",
    "    \n",
    "    a_example_2 = -100\n",
    "    b_example_2 = 200\n",
    "    eps_example_2 = 0.01\n",
    "    \n",
    "    res_example_2 = -1\n",
    "    \n",
    "    assert dichotomous_search_solution(f_example_2, a_example_2, b_example_2, eps_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b023a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dichotomous_search_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65f9ac",
   "metadata": {},
   "source": [
    "# Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_solution(grad_f, x_0, alpha, eps):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума заданной функции двух аргументов с помощью градиентного спуска.\n",
    "    \n",
    "    Аргументы:\n",
    "        grad_f: Градиент функции двух аргументов, для которой необходимо найти минимум.\n",
    "                Функция принимает на вход точку (список из двух значений) и возвращает\n",
    "                вектор градиента в этой точке (тоже список из двух значений).\n",
    "        x_0: Стартовая точка (список из двух значений), из которой запускается алгоритм градиентного спуска.\n",
    "        alpha: Коэффициент скорости обучения.\n",
    "        eps: Минимальное расстояние между текущей точкой градиентного спуска и следующей,\n",
    "             при котором работа алгоритма останавливается.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Координаты точки (список из двух значений), в которой достигается минимальное значение функции.\n",
    "        Каждая координата должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b731c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_test():\n",
    "    f_example_1 = lambda x: x[0] ** 4 + x[1] ** 4\n",
    "    grad_f_example_1 = lambda x: [4 * x[0], 4 * x[1]]\n",
    "    \n",
    "    x_0_example_1 = [32, -4]\n",
    "    \n",
    "    alpha_example_1 = 0.01\n",
    "    eps_example_1 = 0.001\n",
    "    \n",
    "    res_example_1 = [0.02, 0]\n",
    "    \n",
    "    assert gradient_descent_solution(grad_f_example_1, x_0_example_1, alpha_example_1, eps_example_1) == res_example_1\n",
    "    \n",
    "    f_example_2 = lambda x: (x[0] - 1) ** 4 + 2 * (x[1] + 2) ** 2 - 1\n",
    "    grad_f_example_2 = lambda x: [4 * (x[0] - 1) ** 3, 4 * (x[1] + 2)]\n",
    "    \n",
    "    x_0_example_2 = [-2, 2]\n",
    "    \n",
    "    alpha_example_2 = 0.0001\n",
    "    eps_example_2 = 0.0001\n",
    "    \n",
    "    res_example_2 = [0.58, -1.76]\n",
    "    \n",
    "    assert gradient_descent_solution(grad_f_example_2, x_0_example_2, alpha_example_2, eps_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a55763",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e68b85",
   "metadata": {},
   "source": [
    "# Метод имитации отжига"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return 2 * x ** 2 + cos(pi * x) - 2.9 * sin(2 * pi * x) + cos(3 * pi * x) * sin(pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_with_p(random_gen, p, new_x, x):\n",
    "    \"\"\"\n",
    "    С заданной вероятностью возвращает точку `new_x`, в остальных случаях\n",
    "    возвращает точку x.\n",
    "    \n",
    "    Аргументы:\n",
    "        random_gen: Генератор случайных чисел.\n",
    "        p: Вероятность, с которой нужно вернуть первую точку.\n",
    "        new_x: Точка, которая возвращается с вероятностью p.\n",
    "        x: Точка, которая возвращает в остальных случаях.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Точка, которая с вероятностью p будет равна new_x. В противном случае точка будет равна x.\n",
    "    \"\"\"\n",
    "    \n",
    "    val = random_gen.random()\n",
    "    \n",
    "    if val > p:\n",
    "        return x\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e88d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_solution(f, x_0, t_0, lam, eps, random_gen):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума функции с помощью метода имитации отжига.\n",
    "    \n",
    "    Аргументы:\n",
    "        f: Функция, минимум которой необходимо найти.\n",
    "        x_0: Стартовая точка, из которой начинается процесс поиска минимума.\n",
    "        t_0: Начальная температура системы.\n",
    "        lam: Коэффициент охлаждения системы на каждом шаге.\n",
    "             Охлаждение происходит по правилу T = lam * T.\n",
    "        eps: Когда температура становится меньше eps, метод имитации отжига останавливает свою работу.\n",
    "        random_gen: Генератор случайных чисел.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Точка, которую метод считает минимумом функции.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_test():\n",
    "    weierstrass_function = lambda x: 10 + x ** 2 - 10 * cos(2 * pi * x)\n",
    "\n",
    "    f_example_1 = weierstrass_function\n",
    "    \n",
    "    x_0_example_1 = 20\n",
    "    t_0_example_1 = 1000\n",
    "    lam_example_1 = 0.99\n",
    "    eps_example_1 = 0.001\n",
    "    \n",
    "    random_gen_example_1 = random.Random(0)\n",
    "    \n",
    "    res_example_1 = 0.0\n",
    "    \n",
    "    found_min_example_1 = \\\n",
    "        simulated_annealing_solution(weierstrass_function,\n",
    "                                     x_0_example_1,\n",
    "                                     t_0_example_1,\n",
    "                                     lam_example_1,\n",
    "                                     eps_example_1,\n",
    "                                     random_gen_example_1)\n",
    "    \n",
    "    assert round_to_2(weierstrass_function(found_min_example_1)) == res_example_1\n",
    "    \n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_annealing_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
