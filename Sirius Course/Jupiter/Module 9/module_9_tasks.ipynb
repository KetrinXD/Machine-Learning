{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baed4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6415f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed sklearn-0.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: sklearn is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db13d1ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Классический набор данных для проверки качества работы алгоритмов классификации\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_iris\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Классический набор данных для проверки качества работы алгоритмов классификации\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84257982",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (11.7, 8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab592d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_compare(x, y):\n",
    "    if str(x) != str(y):\n",
    "        raise RuntimeError(f'Ожидаемое значение: {y}. Фактическое: {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee8d59",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f46bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skal(v1, v2):\n",
    "    v1, v2 = np.array(v1), np.array(v2)\n",
    "    return sum(v1 * v2)\n",
    "\n",
    "def ziped(l, n):\n",
    "    return [get_col(l, i) for i in range(n)]\n",
    "\n",
    "def get_col(matrix, i):\n",
    "    return [col[i] for col in matrix]\n",
    "\n",
    "def p(w,x):\n",
    "    return 1/(1+np.exp(-skal(x,w)))\n",
    "def round_to_2(x):\n",
    "    return round(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043333a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_predict_solution(w, data, factor_names):\n",
    "    n = len(data[factor_names[0]])\n",
    "    xs = np.array(ziped([[1] * n, *[np.array(data[name]) for name in factor_names]], n))\n",
    "    ps = np.array([round_to_2(p(w,x)) for x in xs])\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc3d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_predict_test():\n",
    "    w_example_1 = np.array([0.1, 1])\n",
    "    data_example_1 = pd.DataFrame({\n",
    "        'x': [0.22, -0.41],\n",
    "    })\n",
    "    \n",
    "    res_example_1 = np.array([0.58, 0.42])\n",
    "    \n",
    "    custom_compare(logistic_regression_predict_solution(w_example_1, data_example_1, ['x']), res_example_1)\n",
    "    \n",
    "    w_example_2 = np.array([0.1, 2.7, 2.3, -4.1])\n",
    "    data_example_2 = pd.DataFrame({\n",
    "        'x': [0.58, 0.15],\n",
    "        'extra': [1, 2],\n",
    "        'y': [0.58, 0.19],\n",
    "        'z': [0.93, 0.44]\n",
    "    })\n",
    "    \n",
    "    res_example_2 = np.array([0.31, 0.3])\n",
    "    \n",
    "    custom_compare(logistic_regression_predict_solution(w_example_2, data_example_2, ['x', 'y', 'z']), res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87daaa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886842b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_summary_loss_gradient_solution(w, X, y):\n",
    "    n = len(y)\n",
    "    grad = 0 \n",
    "    for i in range(n):\n",
    "        grad += y[i] * sum([-y[i]*skal(X[i],w) for i in range(n)])\n",
    "    grad*=-1\n",
    "    print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8424fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_summary_loss_gradient_test():\n",
    "    w_example_1 = np.array([-0.2, -0.3])\n",
    "    X_example_1 = np.array([\n",
    "        [1, -2.1],\n",
    "        [1, 3.7]\n",
    "    ])\n",
    "\n",
    "    y_example_1 = np.array([-1, -1])\n",
    "    \n",
    "    res_example_1 = np.array([0.82, -0.49])\n",
    "    \n",
    "    custom_compare(logistic_summary_loss_gradient_solution(w_example_1, X_example_1, y_example_1), res_example_1)\n",
    "    \n",
    "    w_example_2 = np.array([0.3, -0.1, 0.4])\n",
    "    X_example_2 = np.array([\n",
    "        [1, 0.1, 0.3],\n",
    "        [1, -0.2, 0.5]\n",
    "    ])\n",
    "\n",
    "    y_example_2 = np.array([1, -1])\n",
    "    \n",
    "    res_example_2 = np.array([0.23, -0.17,  0.19])\n",
    "    \n",
    "    custom_compare(logistic_summary_loss_gradient_solution(w_example_2, X_example_2, y_example_2), res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03491b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_summary_loss_gradient_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5777680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_solve_solution(data, factor_names, y_name, \n",
    "                                       learning_rate=0.01, eps=0.1):\n",
    "    \"\"\"\n",
    "    С помощью градиентного спуска строит модель логистической регрессии по переданному набору данных.\n",
    "    \n",
    "    Аргументы:\n",
    "        data: Таблица с объектами обучающей выборки.\n",
    "              Каждый объект описывается набором численных факторов. \n",
    "              В данных может быть представлено больше факторов, чем модель должна использовать для предсказания. \n",
    "              Искусственного константного фактора, который для всех объектов равен 1 и \n",
    "              который будет использоваться моделью для предсказания, в таблице нет.\n",
    "        factor_names: Список названий факторов, которые модель должна использовать для предсказания.\n",
    "        y_name: Название столбца таблицы, в котором для каждого объекта содержится значение предсказываемого класса.\n",
    "                Класс может иметь значение либо -1, либо 1.\n",
    "        learning_rate: Опциональный параметр. Коэффициент скорости обучения, который используется в алгоритме градиентного спуска.\n",
    "        eps: Опциональный параметр. Минимальное расстояние между текущей точкой градиентного спуска и следующей,\n",
    "             при котором работа алгоритма останавливается.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Возвращает вектор весов модели. \n",
    "        Координата вектора с индексом 0 соответствует свободному коэффициенту модели.\n",
    "        Координата вектора с индексом i соответствует фактору с индексом i - 1 в списке factor_names.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = data[factor_names].to_numpy()\n",
    "    y = data[y_name].to_numpy()\n",
    "    \n",
    "    ones = np.ones((len(y), 1))\n",
    "    n = len(y)\n",
    "    \n",
    "    X = np.hstack([ones, X])\n",
    "\n",
    "    # Необходимо задать стартовый набор весов, который является начальной\n",
    "    # точкой для алгоритма градиентного спуска.\n",
    "    # В качестве стартового набора весов необходимо использовать вектор, состоящий из значений 0\n",
    "    w_cur = np.zeros(n)\n",
    "    \n",
    "    while True:\n",
    "        # Вычисление градиента с помощью функции logistic_summary_loss_gradient_solution.\n",
    "        # Важно убрать округление результата работы функции до 2 знаков после запятой\n",
    "        gradient_value = logistic_summary_loss_gradient_solution(w_cur, X, y)\n",
    "    \n",
    "        # Полезно уменьшить значение градиента, разделив каждую его координату на число объектов\n",
    "        # в выборке, на которой происходит обучение модели\n",
    "        gradient_value /= len(y)\n",
    "        \n",
    "        # Классический шаг градиентного спуска: переход из текущей точки в направлении,\n",
    "        # противоположном вектору градиента\n",
    "        w_new = w_cur - gradient_value * learning_rate\n",
    "        \n",
    "        # Проверка того, что расстояние между текущей точкой и новой не стало меньше или равно eps\n",
    "        if np.linalg.norm(w_new - w_curr) <= eps:\n",
    "            break\n",
    "            \n",
    "        w_cur = w_new\n",
    "    \n",
    "    return w_cur.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2834df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_solve_test():\n",
    "    data_example_1 = pd.DataFrame({\n",
    "        'x1': [0.3, -0.1, -0.1, 0.4],\n",
    "        'x2': [0.1, -0.1, 0.2, -0.1],\n",
    "        'y': [1, -1, -1, 1],\n",
    "    })\n",
    "\n",
    "    factor_names_example_1 = ['x1', 'x2']\n",
    "    y_name_example_1 = 'y'\n",
    "    \n",
    "    res_example_1 = np.array([-0.07, 0.94, -0.1])\n",
    "    \n",
    "    custom_compare(logistic_regression_solve_solution(data_example_1, factor_names_example_1, y_name_example_1,\n",
    "                                                      learning_rate=0.001, eps=0.0001),\n",
    "                  res_example_1)\n",
    "    \n",
    "    \n",
    "    iris = load_iris()\n",
    "    \n",
    "    y_example_2 = (iris.target >= 1).astype('int64').reshape((len(iris.target), 1))\n",
    "    y_example_2[y_example_2 == 0] = -1\n",
    "    \n",
    "    factor_names_example_2 = ['x1', 'x2']\n",
    "    y_name_example_2 = 'y'\n",
    "    \n",
    "    data_example_2 = pd.DataFrame(\n",
    "        columns=['x1', 'x2', 'x3', 'x4'] + [y_name_example_2],\n",
    "        data=np.hstack([iris.data, y_example_2])\n",
    "    )\n",
    "    \n",
    "    res_example_2 = np.array([-0.23,  1.17, -1.83])\n",
    "    \n",
    "    custom_compare(logistic_regression_solve_solution(data_example_2, factor_names_example_2, y_name_example_2,\n",
    "                                                      learning_rate=0.01, eps=0.001),\n",
    "                   res_example_2)\n",
    "    \n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d509b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_solve_res():\n",
    "    # Загрузка набора данных для тестирования алгоритмов классификации\n",
    "    iris = load_iris()\n",
    "    \n",
    "    # Приведение классов, которые необходимо научиться предсказывать, к значениям -1 и 1\n",
    "    y = (iris.target > 1).astype('int64').reshape((len(iris.target), 1))\n",
    "    y[y == 0] = -1\n",
    "    \n",
    "    # Создание таблицы на основе набора данных.\n",
    "    # Факторы, которые есть в данных, будут называться 'x1', 'x2', 'x3' и 'x4'.\n",
    "    # Классы объектов помещаются в колонку 'y'\n",
    "    data = pd.DataFrame(\n",
    "        columns=['x1', 'x2', 'x3', 'x4', 'y'],\n",
    "        data=np.hstack([iris.data, y])\n",
    "    )\n",
    "    \n",
    "    # Для предсказания будут использоваться только факторы 'x1' и 'x2'\n",
    "    factor_names = ['x1', 'x2']\n",
    "    # Предсказываемая характеристика — 'y'\n",
    "    y_name = 'y'\n",
    "    \n",
    "    # Определение оптимальных весов для разработанной модели логистической регрессии\n",
    "    ws = logistic_regression_solve_solution(data, factor_names, y_name,\n",
    "                                            learning_rate=0.01, eps=0.001)\n",
    "    \n",
    "    for i in range(len(ws)):\n",
    "        print(f'w{i}:', ws[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7502a459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlogistic_regression_solve_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mlogistic_regression_solve_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m y_name_example_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m res_example_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.07\u001b[39m, \u001b[38;5;241m0.94\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m custom_compare(\u001b[43mlogistic_regression_solve_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_example_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_names_example_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_name_example_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     15\u001b[0m               res_example_1)\n\u001b[0;32m     18\u001b[0m iris \u001b[38;5;241m=\u001b[39m load_iris()\n\u001b[0;32m     20\u001b[0m y_example_2 \u001b[38;5;241m=\u001b[39m (iris\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(iris\u001b[38;5;241m.\u001b[39mtarget), \u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[13], line 41\u001b[0m, in \u001b[0;36mlogistic_regression_solve_solution\u001b[1;34m(data, factor_names, y_name, learning_rate, eps)\u001b[0m\n\u001b[0;32m     36\u001b[0m w_cur \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Вычисление градиента с помощью функции logistic_summary_loss_gradient_solution.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Важно убрать округление результата работы функции до 2 знаков после запятой\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     gradient_value \u001b[38;5;241m=\u001b[39m \u001b[43mlogistic_summary_loss_gradient_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Полезно уменьшить значение градиента, разделив каждую его координату на число объектов\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# в выборке, на которой происходит обучение модели\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     gradient_value \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m, in \u001b[0;36mlogistic_summary_loss_gradient_solution\u001b[1;34m(w, X, y)\u001b[0m\n\u001b[0;32m      3\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m----> 5\u001b[0m     grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y[i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mskal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      6\u001b[0m grad\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(grad)\n",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m----> 5\u001b[0m     grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y[i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m-\u001b[39my[i]\u001b[38;5;241m*\u001b[39m\u001b[43mskal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)])\n\u001b[0;32m      6\u001b[0m grad\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(grad)\n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mskal\u001b[1;34m(v1, v2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mskal\u001b[39m(v1, v2):\n\u001b[0;32m      2\u001b[0m     v1, v2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(v1), np\u001b[38;5;241m.\u001b[39marray(v2)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv2\u001b[49m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (4,) "
     ]
    }
   ],
   "source": [
    "logistic_regression_solve_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3abc9924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: -0.23\n",
      "w1: 1.17\n",
      "w2: -1.83\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_solve_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca44bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
